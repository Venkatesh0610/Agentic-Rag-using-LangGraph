
# ğŸ¤– Agentic RAG using LangGraph

This project implements an **Agentic Retrieval-Augmented Generation (RAG)** system powered by:

- ğŸ§  **LangGraph** for decision-making logic  
- âš¡ **Groq** with LLaMA 3 for ultra-fast LLM inference  
- ğŸ“š **FAISS** + HuggingFace Embeddings for vector-based document retrieval  
- ğŸš€ **FastAPI** for backend and chat API  

> Traditional RAG is passive. Agentic RAG actively decides: â€œShould I search, rewrite, or just answer directly?â€

---
**Check out the video by clicking this :**

[![Watch the video](https://github.com/user-attachments/assets/6148c0c4-d783-4186-9661-c7bb62bfa2a7)](https://youtu.be/qC96fPyvYWA)

---
## ğŸ“Œ Features

- ğŸ§  LangGraph-based agent with branching logic  
- ğŸ” Dynamic decision: retrieve or respond directly  
- âœï¸ Intelligent query rewriting if no context is found  
- ğŸ§¾ Final response generation with or without context  
- âš¡ FastAPI-based API with simple HTML chatbot UI  
- ğŸ“‚ Local FAISS vectorstore with HuggingFace embeddings

---
Want a deeper understanding of how Agentic RAG works behind the scenes?

ğŸ‘‰ Read the full blog here: [Implementing Agentic RAG using LangGraph, Groq & FastAPI](https://pub.towardsai.net/implementing-agentic-rag-using-langgraph-groq-fastapi-e35dacb89548)

---
## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py                  # Fastapi and agentic rag code
â”œâ”€â”€ chatbot_ui.html         # HTML frontend
â”œâ”€â”€ docs/                   # Input documents (markdown or text)
â”œâ”€â”€ vectorstore/            # Saved FAISS index and pickle files
â”œâ”€â”€ requirements.txt        # All dependencies

````

---

## ğŸ§  Agentic RAG Flow
<img width="274" height="456" alt="image" src="https://github.com/user-attachments/assets/0bb21c09-06bf-40cb-8860-931ba4eb2775" />

* If relevant documents are found: answer using context
* If not: rewrite the query and try again
* If still irrelevant: answer directly using the LLM

---
